import pandas as pd
sample_submission = pd.read_csv
#test_df shows Ecommerce transactions and associated loans from 31 March 2019 and 17 July 2019, excluding whether or not a customer defaulted on their loan.
#Additional variables associated with the loan have also been removed from the test set.
#This is the dataset that you will use to test your model on.
test_df = pd.read_csv('/Users/chagwon-u/Desktop/Project/Loan Default Prediction Challenge/test.csv')
#train_df shows ecommerce transactions and associated loans from 21 September 2018 and 31 March 2019, including whether or not a customer defaulted on their loan.
#This is the dataset that I will use to train my model.
train_df = pd.read_csv('/Users/chagwon-u/Desktop/Project/Loan Default Prediction Challenge/train.csv')
#e-commerce transactions not linked to any loans, but associated to customers with loan-linked e-commerce transactions.
#Compare train data columns and maked_final_only columns
masked_final = pd.read_csv('/Users/chagwon-u/Desktop/Project/Loan Default Prediction Challenge/unlinked_masked_final.csv')
#Compare train data columns and maked_final_only columns
columns_train = set(train_df.columns)
columns_masked = set(masked_final.columns)
#columns_in_original_data_only
columns_train - columns_masked
#columns_in_maked_final_only
columns_masked - columns_train
train_df.info()
#check missing values in train df
print(train_df.isnull().sum())
import pandas as pd
import pandas_profiling
from pandas_profiling import ProfileReport
profile = pandas_profiling.ProfileReport(train_df, title="Data Profile Report",  minimal=True)
profile.to_file(output_file="profile.html")
#delete the rows that have null value
train_df_cleaned = train_df.dropna(inplace=False)
train_df_cleaned.info()
import category_encoders as ce
oce = ce.OneHotEncoder(cols=['ProductCategory'])
df_encoded = oce.fit_transform(train_df_cleaned)
#feature selection
target = 'IsDefaulted'
correlations = train_df_cleaned.corrwith(train_df_cleaned[target])
correlations_sorted = correlations.sort_values(ascending=False)
print(correlations_sorted)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn import metrics

# Assuming you have your training data (train_df_cleaned) and test data (test_df)
X_train = train_df_cleaned[['Value', 'Amount']]
y_train = train_df_cleaned['IsDefaulted']

# Split the training data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Create a StandardScaler and fit it on the training data
scaler = StandardScaler()
scaler.fit(X_train)

# Transform the training and validation data
X_train_scaled = scaler.transform(X_train)
X_val_scaled = scaler.transform(X_val)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

# Transform the test data using the same scaler
X_test_scaled = scaler.transform(test_df[['Value', 'Amount']])

# Predict using the trained logistic regression model
new_predictions = model.predict(X_test_scaled)

# Display predictions
print(new_predictions)
